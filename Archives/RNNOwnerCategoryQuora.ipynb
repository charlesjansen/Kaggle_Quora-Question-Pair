{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Owner Categorization with an RNN\n",
    "\n",
    "In this notebook, I will implement a recurrent neural network that categorize owners base on their name. Using an RNN rather than a feedfoward network is more accurate since we can include information about the *sequence* of words. Here we'll use a dataset of owners name from the Philipines and India.\n",
    "\n",
    "The architecture for this network is shown below.\n",
    "\n",
    "Here, we'll pass in words to an embedding layer.\n",
    "\n",
    "From the embedding layer, the new representations will be passed to LSTM cells. These will add recurrent connections to the network so we can include information about the sequence of words in the data. Finally, the LSTM cells will go to a sigmoid output layer here. The output layer will just be a single unit then, with a sigmoid activation function.\n",
    "\n",
    "We are not interested in the sigmoid outputs except for the very last one, we can ignore the rest. We'll calculate the cost from the output of the last step and the training label.\n",
    "\n",
    "Charles Jansen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TRAIN_DATA_FILE = 'F:/DS-main/Kaggle-main/Quora Question Pairs - inputs/data/finalTrain.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pd = pd.read_csv(TRAIN_DATA_FILE, sep='\\t', encoding=\"utf-8\", usecols=[0])\n",
    "preg1_pd = pd.read_csv(TRAIN_DATA_FILE, sep='\\t', encoding=\"utf-8\", usecols=[1])\n",
    "preg2_pd = pd.read_csv(TRAIN_DATA_FILE, sep='\\t', encoding=\"utf-8\", usecols=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 1 columns):\n",
      "2    404288 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "preg2_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   2\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What would happen if the Indian government sto...\n",
       "2  How can Internet speed be increased by hacking...\n",
       "3  Find the remainder when [math]23^{24}[/math] i...\n",
       "4            Which fish would survive in salt water?"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preg2_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_pd))\n",
    "y = y_pd.values\n",
    "preg1 = preg1_pd.values\n",
    "preg2 = preg2_pd.values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [ligne[0] for _,ligne in enumerate(y)]\n",
    "preg1 = [str(ligne[0]) for _,ligne in enumerate(preg1)]\n",
    "preg2 = [str(ligne[0]) for _,ligne in enumerate(preg2)]\n",
    "y[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404290\n",
      "404290\n",
      "404290\n",
      "808580\n",
      "808580\n",
      "808580\n"
     ]
    }
   ],
   "source": [
    "preg1temp = preg1\n",
    "print(len(y))\n",
    "print(len(preg1))\n",
    "print(len(preg2))\n",
    "y.extend(y)\n",
    "preg1 = preg1 + preg2\n",
    "preg2.extend(preg1temp)\n",
    "print(len(y))\n",
    "print(len(preg1))\n",
    "print(len(preg2))\n",
    "del(preg1temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the step by step guide to invest in share market in india?', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?', 'How can I increase the speed of my internet connection while using a VPN?']\n",
      "['What is the step by step guide to invest in share market?', 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', 'How can Internet speed be increased by hacking through DNS?']\n",
      "[0, 0, 0]\n",
      "['What is the step by step guide to invest in share market?', 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', 'How can Internet speed be increased by hacking through DNS?']\n",
      "['What is the step by step guide to invest in share market in india?', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?', 'How can I increase the speed of my internet connection while using a VPN?']\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(preg1[:3])\n",
    "print(preg2[:3])\n",
    "print(y[:3])\n",
    "print(preg1[404290:404293])\n",
    "print(preg2[404290:404293])\n",
    "print(y[404290:404293])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Since we're using embedding layers, we'll need to encode each word with an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = ' '.join(preg1)\n",
    "words = all_words.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the step by step guide to invest in share market in india? What is the story of Kohinoor (Koh-i-Noor) Diamond? How can I increase the speed of my internet connection while using a VPN? Why am I mentally very lonely? How can I solve it? Which one dissolve in water quikly sugar, salt, methane and carbon di oxide? Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? Should I buy tiago? How can I be a good geologist? When do you use ? instead of ?? Motorola (company): Can I hack my Charter Motorolla DCX3400? Method to find separation of slits using fresnel biprism? How do I read and find my YouTube comments? What can make Physics easy to learn? What was your first sexual experience like? What are the laws to change your status from a student visa to a green card in the US, how do they compare to the immigration laws in Canada? What would a Trump presidency mean for current international master\\x92s students on an F1 visa? What does manipulation mean? '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8944869"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'is',\n",
       " 'the',\n",
       " 'step',\n",
       " 'by',\n",
       " 'step',\n",
       " 'guide',\n",
       " 'to',\n",
       " 'invest',\n",
       " 'in',\n",
       " 'share',\n",
       " 'market',\n",
       " 'in',\n",
       " 'india?',\n",
       " 'What',\n",
       " 'is',\n",
       " 'the',\n",
       " 'story',\n",
       " 'of',\n",
       " 'Kohinoor']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the words\n",
    "\n",
    "The embedding lookup requires that we pass in integers to our network. The easiest way to do this is to create dictionaries that map the words in the vocabulary to integers. Then we can convert each of our owner names into integers so they can be passed into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii-1 for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "preg1_ints = []\n",
    "preg2_ints = []\n",
    "for each in preg1:\n",
    "    preg1_ints.append([vocab_to_int[word]+1 for word in each.split()])\n",
    "for each in preg2:\n",
    "    preg2_ints.append([vocab_to_int[word]+1 for word in each.split()])\n",
    "###+1 because I pad with 0 and I had a word 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'What', 'is', 'I', 'a']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231656"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the labels \n",
    "\n",
    "Our labels are \"company\" or \"person\". To use these labels in our network, we need to convert them to 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808580\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(preg1_ints))\n",
    "print(type(preg1_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length preg1: 0\n",
      "Maximum preg1 length: 237\n",
      "Zero-length preg2: 0\n",
      "Maximum preg2 length: 237\n"
     ]
    }
   ],
   "source": [
    "preg1_lens = Counter([len(x) for x in preg1_ints])\n",
    "print(\"Zero-length preg1: {}\".format(preg1_lens[0]))\n",
    "print(\"Maximum preg1 length: {}\".format(max(preg1_lens)))\n",
    "\n",
    "preg2_lens = Counter([len(x) for x in preg2_ints])\n",
    "print(\"Zero-length preg2: {}\".format(preg2_lens[0]))\n",
    "print(\"Maximum preg2 length: {}\".format(max(preg2_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For names shorter than 28, we'll pad with 0s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 40\n",
    "features1 = np.zeros((len(preg1_ints), seq_len), dtype=int)\n",
    "for i, row in enumerate(preg1_ints):\n",
    "    features1[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      2,      3,      1,   1413,     55,   1413,\n",
       "          3324,      6,    515,      8,    750,    597,      8,    781],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             2,      3,      1,    775,      9,  19803,  42892,  47069],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      7,     14,      4,    193,      1,    472,\n",
       "             9,     18,    799,   2644,    189,    137,      5,   8131],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,     16,     75,      4,\n",
       "          3027,    265,   5514,      7,     14,      4,    559,    122],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,     31,     53,   8706,      8,    293,\n",
       "         68328,  35568,  45567,  22134,     12,   2211,  25598,  14773],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "         15645,      4,     75,      5,  17368,   2596,  45272,   1879,\n",
       "            12,   7501, 192284,     22,     26,    236,     46,    205],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,    106,      4,    129, 184308],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      7,     14,      4,     24,      5,     38,  73211],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "           115,     10,     15,     78,    213,    438,      9,   3521],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,   8888,\n",
       "         12627,     36,      4,    435,     18,  19729, 112864, 128369]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 40\n",
    "features2 = np.zeros((len(preg2_ints), seq_len), dtype=int)\n",
    "for i, row in enumerate(preg2_ints):\n",
    "    features2[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      2,      3,      1,   1413,\n",
       "            55,   1413,   3324,      6,    515,      8,    750,    905],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      2,     43,    187,     35,      1,\n",
       "            89,    301,  14780,      1,  19803,  42892,   8259,    956],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      7,     14,\n",
       "          1528,    472,     24,   4335,     55,   2230,    192,  39218],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,   4247,\n",
       "             1,   4580,     47, 193883,      3,   2519,     55, 179596],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,     31,   2421,     43,   1339,      8,   2433,    817]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.concatenate((features1,np.zeros((len(features1), 5), dtype=int),features2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      2,      3,      1,   1413,     55,   1413,\n",
       "          3324,      6,    515,      8,    750,    597,      8,    781,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      2,      3,      1,   1413,     55,   1413,   3324,\n",
       "             6,    515,      8,    750,    905],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             2,      3,      1,    775,      9,  19803,  42892,  47069,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             2,     43,    187,     35,      1,     89,    301,  14780,\n",
       "             1,  19803,  42892,   8259,    956],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      7,     14,      4,    193,      1,    472,\n",
       "             9,     18,    799,   2644,    189,    137,      5,   8131,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      7,     14,   1528,    472,     24,\n",
       "          4335,     55,   2230,    192,  39218],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,     16,     75,      4,\n",
       "          3027,    265,   5514,      7,     14,      4,    559,    122,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,   4247,      1,   4580,     47,\n",
       "        193883,      3,   2519,     55, 179596],\n",
       "       [     0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,     31,     53,   8706,      8,    293,\n",
       "         68328,  35568,  45567,  22134,     12,   2211,  25598,  14773,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,     31,   2421,\n",
       "            43,   1339,      8,   2433,    817]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data in nice shape, we'll split it into training, validation, and test sets.\n",
    "\n",
    "10% randomly taken for test.\n",
    "\n",
    "Kfold on the remaining 90% for validation and training.-->canceled. Done, but took much more time for the same 98.9 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "X\n",
      "Train set: \t\t(654949, 85) \n",
      "Validation set: \t(72773, 85) \n",
      "Test set: \t\t(80858, 85) \n",
      "Y\n",
      "Train set: \t\t(654949,) \n",
      "Validation set: \t(72773,) \n",
      "Test set: \t\t(80858,)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.9\n",
    "train_val_x, test_x, train_val_y, test_y = train_test_split(\n",
    "    features, y, \n",
    "    train_size = split_frac)\n",
    "\n",
    "#sin Kfold\n",
    "train_x, val_x, train_y, val_y = train_test_split(\n",
    "    train_val_x, train_val_y, \n",
    "    train_size = split_frac)\n",
    "'''\n",
    "#Kfold\n",
    "train_x = []\n",
    "val_x   = []\n",
    "train_y = []\n",
    "val_y   = []\n",
    "train_x =  np.empty([0,max(names_lens)])\n",
    "val_x   =  np.empty([0,max(names_lens)])\n",
    "train_y =  np.empty(0)\n",
    "val_y   =  np.empty(0)\n",
    "\n",
    "kf = KFold(n_splits = 9, shuffle=True)\n",
    "for train_index, val_index in kf.split(train_val_x):\n",
    "    train_temp_x, val_temp_x = train_val_x[train_index], train_val_x[val_index]\n",
    "    train_temp_y, val_temp_y = train_val_y[train_index], train_val_y[val_index]\n",
    "    train_x = np.concatenate((train_x, train_temp_x), axis=0)\n",
    "    val_x   = np.concatenate((val_x, val_temp_x), axis=0)\n",
    "    train_y = np.concatenate((train_y, train_temp_y), axis=0)\n",
    "    val_y = np.concatenate((val_y, val_temp_y), axis=0)\n",
    "\n",
    "'''\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"X\\nTrain set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape),\n",
    "      \"\\nY\\nTrain set: \\t\\t{}\".format(train_y.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_y.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_y.shape),\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(y_pd, preg1_pd, preg2_pd, preg1, preg2, preg1_ints, preg2_ints, features1, features2, features, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph\n",
    "\n",
    "Here, we'll build the graph. First up, defining the hyperparameters.\n",
    "\n",
    "* `lstm_size`: Number of units in the hidden layers in the LSTM cells. \n",
    "* `lstm_layers`: Number of LSTM layers in the network. I'd start with 1, then add more if I'm underfitting.\n",
    "* `batch_size`: The number of names to feed the network in one training pass.\n",
    "* `learning_rate`: Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 64\n",
    "lstm_layers = 1\n",
    "batch_size = 8\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the network itself, we'll be passing in our 28 element long names vectors. Each batch will be `batch_size` vectors. We'll also be using dropout on the LSTM layer, so we'll make a placeholder for the keep probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int)\n",
    "\n",
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "# Add nodes to the graph\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Now we'll add an embedding layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231656"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'What',\n",
       " 'is',\n",
       " 'I',\n",
       " 'a',\n",
       " 'to',\n",
       " 'How',\n",
       " 'in',\n",
       " 'of',\n",
       " 'do',\n",
       " 'are',\n",
       " 'and',\n",
       " 'for',\n",
       " 'can',\n",
       " 'you',\n",
       " 'Why',\n",
       " 'best',\n",
       " 'my',\n",
       " 'on',\n",
       " 'it']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of the embedding vectors (number of units in the embedding layer)\n",
    "embed_size = 300 \n",
    "\n",
    "with graph.as_default():\n",
    "    embedding = tf.Variable(tf.truncated_normal((n_words, embed_size), stddev=0.1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM cell\n",
    "\n",
    "\n",
    "\n",
    "Next, we'll create our LSTM cells to use in the recurrent network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Your basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN forward pass\n",
    "\n",
    "\n",
    "Now we need to actually run the data through the RNN nodes. \n",
    "\n",
    "Above I created an initial state, `initial_state`, to pass to the RNN. This is the cell state that is passed between the hidden layers in successive time steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
    "                                             initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "We want the final output. So we need to grab the last output with `outputs[:, -1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy\n",
    "\n",
    "Here we can add a few nodes to calculate the accuracy which we'll use in the validation pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching\n",
    "\n",
    "This is a simple function for returning batches from our data. First it removes data such that we only have full batches. Then it iterates through the `x` and `y` arrays and returns slices out of those arrays with size `[batch_size]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "epochs = 1\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, 2), 1):\n",
    "            print(ii)\n",
    "            print(x)\n",
    "            print(y)\n",
    "            print(x.shape)\n",
    "            print(y.shape)\n",
    "            print(y[:, None])\n",
    "            if ii == 5:\n",
    "                raise Exception(\"Manual Stop\")\n",
    "#''' ;           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[231656,300]\n\t [[Node: Adam/update_Variable/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable/Adam/read, Adam/beta1)]]\n\t [[Node: mean_squared_error/value/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_509_mean_squared_error/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Adam/update_Variable/mul_2', defined at:\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-616d62ee52be>\", line 5, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 325, in minimize\n    name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 456, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 102, in update_op\n    return optimizer._apply_sparse_duplicate_indices(g, self._v)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 654, in _apply_sparse_duplicate_indices\n    return self._apply_sparse(gradient_no_duplicate_indices, var)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 168, in _apply_sparse\n    m_t = state_ops.assign(m, m * beta1_t,\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 667, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 821, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1044, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1434, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[231656,300]\n\t [[Node: Adam/update_Variable/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable/Adam/read, Adam/beta1)]]\n\t [[Node: mean_squared_error/value/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_509_mean_squared_error/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[231656,300]\n\t [[Node: Adam/update_Variable/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable/Adam/read, Adam/beta1)]]\n\t [[Node: mean_squared_error/value/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_509_mean_squared_error/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-e8e84d6bb5e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     initial_state: state}\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[231656,300]\n\t [[Node: Adam/update_Variable/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable/Adam/read, Adam/beta1)]]\n\t [[Node: mean_squared_error/value/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_509_mean_squared_error/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Adam/update_Variable/mul_2', defined at:\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-616d62ee52be>\", line 5, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 325, in minimize\n    name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 456, in apply_gradients\n    update_ops.append(processor.update_op(self, grad))\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 102, in update_op\n    return optimizer._apply_sparse_duplicate_indices(g, self._v)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 654, in _apply_sparse_duplicate_indices\n    return self._apply_sparse(gradient_no_duplicate_indices, var)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 168, in _apply_sparse\n    m_t = state_ops.assign(m, m * beta1_t,\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 667, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 821, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1044, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1434, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\ProgramData\\Anaconda3\\envs\\t\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[231656,300]\n\t [[Node: Adam/update_Variable/mul_2 = Mul[T=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Variable/Adam/read, Adam/beta1)]]\n\t [[Node: mean_squared_error/value/_21 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_509_mean_squared_error/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%250==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:, None],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/ownerNameCategQuora.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, None],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0 2491 1080]]\n"
     ]
    }
   ],
   "source": [
    "x = \"Dushyant Sekhar \"\n",
    "\n",
    "x_int = [vocab_to_int[word] for word in x.split()]\n",
    "x_int = x_int[:28] #ignore words after 28th\n",
    "\n",
    "x_int_sized = np.zeros((1,seq_len), dtype=int)\n",
    "x_int_sized[0,-len(x_int):] = np.array(x_int)[:seq_len]\n",
    "print(x_int_sized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fillerSize =  batch_size - 1\n",
    "filler = np.tile(np.zeros((1, seq_len), dtype=int),(fillerSize,1))\n",
    "#print(filler.shape)\n",
    "prodBatch = np.append(x_int_sized,filler, axis=0)\n",
    "#print(prodBatch)\n",
    "#print(prodBatch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00042518]\n",
      "Dushyant Sekhar  \n",
      "Person\n",
      "probability 99.96%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    feed = {inputs_: prodBatch,\n",
    "            keep_prob: 1,\n",
    "            initial_state: test_state}\n",
    "    output = sess.run(predictions, feed_dict=feed)\n",
    "    print(output[0])\n",
    "    if output[0]>0.5:\n",
    "        print(x,\"\\nCompany\")\n",
    "        print(\"probability {}%\".format(np.round(output[0][0]*100,2)))\n",
    "    else:\n",
    "        print(x,\"\\nPerson\")\n",
    "        print(\"probability {}%\".format(np.round(100-output[0][0]*100,2)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
